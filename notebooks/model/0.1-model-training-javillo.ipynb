{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# sys.path.append(os.path.abspath(\"../..\"))\n",
    "# from wine_quality import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this EDA is to visualize the patterns in the wine dataset and their interaction with quality. The question to be answered is: what are the components of win that affect its quality.\n",
    "\n",
    "This part combines the red and white datasets and adds a new feature (is_red) to distinguish the color of the wine. Each numerical feature was standardized to better visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>is_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4              0.70         0.00             1.9      0.076   \n",
       "1               7.8              0.88         0.00             2.6      0.098   \n",
       "2               7.8              0.76         0.04             2.3      0.092   \n",
       "3              11.2              0.28         0.56             1.9      0.075   \n",
       "4               7.4              0.70         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6492            6.2              0.21         0.29             1.6      0.039   \n",
       "6493            6.6              0.32         0.36             8.0      0.047   \n",
       "6494            6.5              0.24         0.19             1.2      0.041   \n",
       "6495            5.5              0.29         0.30             1.1      0.022   \n",
       "6496            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  is_red  \n",
       "0         9.4        5       1  \n",
       "1         9.8        5       1  \n",
       "2         9.8        5       1  \n",
       "3         9.8        6       1  \n",
       "4         9.4        5       1  \n",
       "...       ...      ...     ...  \n",
       "6492     11.2        6       0  \n",
       "6493      9.6        5       0  \n",
       "6494      9.4        6       0  \n",
       "6495     12.8        7       0  \n",
       "6496     11.8        6       0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets using .env variable\n",
    "# red_raw_df = dataset.load_raw_data(\"winequality-red.csv\", \";\")\n",
    "# white_raw_df = dataset.load_raw_data(\"winequality-white.csv\", \";\")\n",
    "\n",
    "#Load datasets locally\n",
    "red_raw_df = pd.read_csv(\"../../data/raw/winequality-red.csv\", delimiter=\";\")\n",
    "white_raw_df = pd.read_csv(\"../../data/raw/winequality-white.csv\", delimiter=\";\")\n",
    "\n",
    "\n",
    "# Add 'is_red' column (1 for red, 0 for white)\n",
    "red_raw_df[\"is_red\"] = 1\n",
    "white_raw_df[\"is_red\"] = 0\n",
    "\n",
    "# Combine datasets\n",
    "combined_raw_df = pd.concat([red_raw_df, white_raw_df], ignore_index=True)\n",
    "\n",
    "display(combined_raw_df)\n",
    "# # Select features for scaling and encoding. Removed encoding, since there are not categorical values\n",
    "# bool_features = combined_raw_df.select_dtypes(include=[np.number, 'bool']).columns[combined_raw_df.nunique() == 2].tolist()\n",
    "# # cat_features = combined_raw_df.select_dtypes(include=[\"object\"]).columns.tolist() \n",
    "\n",
    "# print(num_features)\n",
    "# print(bool_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training\n",
    "1) Categorization model for predicting whether wine is red or white\n",
    "2) Regression model for predicting quality for all wines\n",
    "3) Regression model for predicting quality for red wines\n",
    "4) Regression model for predicting quality for white wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning for using regression for quality prediction.\n",
    "\n",
    "At first glance, there are three ways of predicting quality, First, is categorization with each quality as a class (3,4,5,6,7,and 8). This however wil be more complex than it should be because of its multi-class nature. Second is condensing quality into three levels: low, medium, and high. This is simpler because there a smaller number of categories but I am not an expert on classifying wines in such ways and I am not sure on which quality levels should be in low, medium, or high. The third option is regression; this option outputs a real number instead of a class. So it might predict a wine to be 4.5, 6.9, or 3.2. These quality levels are not present in the dataset but is still very useful since it treats quality as a scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C values per class: [10.]\n",
      "Test Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       0.99      0.99      0.99       320\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose target column\n",
    "X = combined_raw_df.drop(columns=[\"is_red\"])  # Features\n",
    "y = combined_raw_df[\"is_red\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=[np.number]).columns[X.nunique() > 2].tolist()\n",
    "\n",
    "cat_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_scaler\", StandardScaler(), num_features),  # Scale numerical\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Define Logistic Regression with automatic cross-validation\n",
    "model = LogisticRegressionCV(\n",
    "    Cs=np.logspace(-3, 3, 7),\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", cat_preprocessor),\n",
    "    (\"classifier\", model)\n",
    "])\n",
    "\n",
    "# Train the pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print Best C Values for Each Class\n",
    "print(f\"Best C values per class: {pipeline.named_steps['classifier'].C_}\")\n",
    "\n",
    "# Model Evaluation\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE: 0.5435\n",
      "Cross-Validation RÂ²: 0.2869\n",
      "Test MSE: 0.5364\n",
      "Test RÂ²: 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Documents\\AI_Projects\\wine\\wine_quality\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\Documents\\AI_Projects\\wine\\wine_quality\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Choose target column\n",
    "X = combined_raw_df.drop(columns=[\"quality\"])  # Features\n",
    "y = combined_raw_df[\"quality\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=[np.number]).columns[X.nunique() > 2].tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_scaler\", StandardScaler(), num_features),  # Scale numerical\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Identify numerical columns (all are numerical in this dataset)\n",
    "num_features = list(range(X.shape[1]))\n",
    "\n",
    "# Define Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"regressor\", model)\n",
    "])\n",
    "\n",
    "# Stratified K-Fold Cross-Validation on Training Data (70%)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_mse = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='neg_mean_squared_error')\n",
    "cross_val_r2 = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='r2')\n",
    "\n",
    "print(f\"Cross-Validation MSE: {-np.mean(cross_val_mse):.4f}\")\n",
    "print(f\"Cross-Validation RÂ²: {np.mean(cross_val_r2):.4f}\")\n",
    "\n",
    "# Train the final model on the full training data (70%)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Final Testing on 30% Test Set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test RÂ²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in chemical composition between red and white might have an effect to the quality level. The chemical composition of a high quality red wine might be different form a high quality white wine. Thus, two separated models were created for red and white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE: 0.4276\n",
      "Cross-Validation RÂ²: 0.3458\n",
      "Test MSE: 0.4064\n",
      "Test RÂ²: 0.3703\n"
     ]
    }
   ],
   "source": [
    "# Choose target column\n",
    "X = red_raw_df.drop(columns=[\"quality\"])  # Features\n",
    "y = red_raw_df[\"quality\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=[np.number]).columns[X.nunique() > 2].tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_scaler\", StandardScaler(), num_features),  # Scale numerical\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Identify numerical columns (all are numerical in this dataset)\n",
    "num_features = list(range(X.shape[1]))\n",
    "\n",
    "# Define Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"regressor\", model)\n",
    "])\n",
    "\n",
    "# Stratified K-Fold Cross-Validation on Training Data (70%)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_mse = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='neg_mean_squared_error')\n",
    "cross_val_r2 = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='r2')\n",
    "\n",
    "print(f\"Cross-Validation MSE: {-np.mean(cross_val_mse):.4f}\")\n",
    "print(f\"Cross-Validation RÂ²: {np.mean(cross_val_r2):.4f}\")\n",
    "\n",
    "# Train the final model on the full training data (70%)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Final Testing on 30% Test Set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test RÂ²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for red did better than the combined model with an r2 score of 0.3703 and 0.2975 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE: 0.5672\n",
      "Cross-Validation RÂ²: 0.2766\n",
      "Test MSE: 0.5794\n",
      "Test RÂ²: 0.2619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Documents\\AI_Projects\\wine\\wine_quality\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pc\\Documents\\AI_Projects\\wine\\wine_quality\\env\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose target column\n",
    "X = white_raw_df.drop(columns=[\"quality\"])  # Features\n",
    "y = white_raw_df[\"quality\"]\n",
    "\n",
    "num_features = X.select_dtypes(include=[np.number]).columns[X.nunique() > 2].tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num_scaler\", StandardScaler(), num_features),  # Scale numerical\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Identify numerical columns (all are numerical in this dataset)\n",
    "num_features = list(range(X.shape[1]))\n",
    "\n",
    "# Define Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Define full pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"regressor\", model)\n",
    "])\n",
    "\n",
    "# Stratified K-Fold Cross-Validation on Training Data (70%)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_mse = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='neg_mean_squared_error')\n",
    "cross_val_r2 = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='r2')\n",
    "\n",
    "print(f\"Cross-Validation MSE: {-np.mean(cross_val_mse):.4f}\")\n",
    "print(f\"Cross-Validation RÂ²: {np.mean(cross_val_r2):.4f}\")\n",
    "\n",
    "# Train the final model on the full training data (70%)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Final Testing on 30% Test Set\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test RÂ²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for white however did poorer than the combined model and the red model suggesting that the quality for white wines is harder to predict with linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
